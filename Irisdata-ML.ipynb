{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network to identify the flowers type using the Iris data \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model, metrics, model_selection, datasets\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\n",
    "    \"\"\"\n",
    "    return 1.0 / ( 1.0 + np.exp(-z))\n",
    "\n",
    "def devsigmoid(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\n",
    "    \"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "class arrays(object):\n",
    "    \"\"\"To generate the ramdon matrices for each layer\n",
    "    \"\"\"\n",
    "    def __init__(self, row=None, col=None,seeds=None):\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "        self.seeds= seeds\n",
    "          \n",
    "    def matrix(self):\n",
    "        np.random.seed(self.seeds)\n",
    "        if self.col == 1:\n",
    "            return np.random.rand(self.row)\n",
    "        elif self.row == 1:\n",
    "            return np.random.rand(self.col)\n",
    "        else:\n",
    "            return np.random.rand(self.row, self.col)\n",
    "        \n",
    "    def vec(self):\n",
    "        np.random.seed(77 * self.seeds + 29)\n",
    "        return np.random.rand(self.row)\n",
    "    \n",
    "def resta(v1, v2):\n",
    "    \"\"\"Function to substract vectors of any size.\n",
    "        len(v1) = len(v2)\n",
    "    \"\"\"    \n",
    "    if len(v1) > 1:\n",
    "        vec=[]\n",
    "        for i in range(len(v1)):\n",
    "            vec.append((v1[i] - v2[i]))\n",
    "    else:\n",
    "        vec = np.array(v1) - np.array(v2)\n",
    "    return np.array(vec)\n",
    "\n",
    "def transres(values, options):\n",
    "    \"\"\"Transform data input results into vectors of\n",
    "       the size of the element of the last layer\n",
    "    \"\"\"    \n",
    "    if options == 1 :\n",
    "        return np.array(values)\n",
    "    else:\n",
    "        newvec = np.zeros(options)\n",
    "        newvec[values] = 1\n",
    "        return newvec\n",
    "\n",
    "#**************************************************************#\n",
    "#---------------------- back_propagationagation -----------------------#\n",
    "#------------------------------------------------ -------------#   \n",
    "def back_propagation(M, bb, valout, y, yp, siz, eta):\n",
    "    \"\"\" Input:\n",
    "            M = coeficcients matrix\n",
    "            bb = bias \n",
    "            valout = value predicted\n",
    "            y = data input (previous value got from feed_forwardard)\n",
    "            yp = value expected \n",
    "        Return    \n",
    "            M = list of ndarrays. It contains the calculated weigths for each layer (for one epoch)\n",
    "            bb = list of ndarrays. It contains the calculated bias for each layer (for one epoch)\n",
    "\n",
    "    \"\"\"\n",
    "#--------------------------- Beginning ------------------------#\n",
    "#------------------- Code to get the first delta --------------#\n",
    "    dim0 = np.reshape(M[siz - 2], (len(M[siz - 2]), -1))\n",
    "    xsiz, ysiz = np.shape(dim0)\n",
    "    cost = resta(valout, yp)\n",
    "    if ysiz <= 1:\n",
    "        z = np.dot(M[siz - 2].T, y[siz - 2]) + bb[siz - 2]\n",
    "        delta = 2 * cost * devsigmoid(z)\n",
    "    else:  \n",
    "        z = np.matmul(M[siz - 2], y[siz - 2]) + bb[siz-2]\n",
    "        z1 = len(z)\n",
    "        delta0 = []\n",
    "        for i in range(z1):\n",
    "            delta0.append(2 * cost[i] * devsigmoid(z[i]))\n",
    "        delta = np.reshape(np.array(delta0), (z1, 1)) \n",
    "#------------------------------------------------------------------#\n",
    "    for k in range(siz - 2, -1, -1):\n",
    "        nabla_w1 = []\n",
    "        y2 = y[k]\n",
    "        siz1, siz2 = len(y2), len(delta)\n",
    "        bb[k] = np.array(bb[k])\n",
    "        for i in range(siz1):\n",
    "            for j in range(siz2):\n",
    "                nabla_w1.append(eta * y2[i] * delta[j]) \n",
    "        nabla_w = np.reshape(np.array(nabla_w1), (siz1, siz2))        \n",
    "        nabla_b = (eta * delta)\n",
    "        if len(np.atleast_1d(delta)) == 1:\n",
    "            suma = M[k] * delta\n",
    "            M[k] = (M[k] - nabla_w )\n",
    "        else:\n",
    "            suma = np.matmul(M[k].T, delta)\n",
    "            M[k] = (M[k] - nabla_w.T)\n",
    "        bb[k] = bb[k] - nabla_b\n",
    "        if k >= 1 :\n",
    "            y2 = np.reshape(y[k - 1], (len(y[k - 1]), 1))\n",
    "            z = np.matmul(M[k - 1], y2) + bb[k - 1]\n",
    "            junto = []\n",
    "            for j in range(len(z)):\n",
    "                junto.append(suma[j] * devsigmoid(z[j]))\n",
    "            delta = np.reshape(np.array(junto), (len(z), 1))\n",
    "            nabla_w = []       \n",
    "    return (M, bb)   \n",
    "\n",
    "#**************************************************************#\n",
    "#----------------------- feed_forwardard --------------------------#\n",
    "#--------------------------------------------------------------# \n",
    "def feed_forward(w, vals, bbb, size_sys):\n",
    "    \"\"\" \n",
    "        Input:\n",
    "            w = list of ndarrays. It contains the calculated weigths for each layer\n",
    "            vals = numpy array. Row from the dataset \n",
    "            bbb = list of ndarrays. It contains the calculated bias for each layer\n",
    "            size_sys = integer. Number of hidden layers \n",
    "        Return:\n",
    "            fval = numpy array. It contains the output of each layer\n",
    "    \"\"\"  \n",
    "    fval = []\n",
    "    vals = np.reshape(vals, (len(vals), 1))\n",
    "    for j in range(size_sys - 1):\n",
    "        w[j] = np.array(w[j])\n",
    "        if len(np.atleast_1d(bbb[j])) == 1:\n",
    "            valor = []\n",
    "            bbb[j] = bbb[j]\n",
    "            w[j] = np.reshape(w[j], (len(w[j]), -1))\n",
    "            vals = np.dot(w[j].T, vals) + np.array(bbb[j])\n",
    "            for i in range(len(vals)):\n",
    "                valor.append(sigmoid(vals[i]))\n",
    "            vals = np.array(valor) \n",
    "        else:\n",
    "            valor = []\n",
    "            bbb[j] = np.reshape(bbb[j], (len(bbb[j]), 1))\n",
    "            vals = np.matmul(w[j], vals) + np.array(bbb[j])\n",
    "            for i in range(len(vals)):\n",
    "                valor.append(sigmoid(vals[i]))\n",
    "            vals = np.array(valor)  \n",
    "        fval.append(vals)\n",
    "    fval = np.array(fval)   \n",
    "    return fval\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "#***************************  Neural Network   **************************# \n",
    "#------------------------------------------------------------------------#\n",
    "#------------------------------------------------------------------------#\n",
    "def network(vec, indat, res, eta, tol, epochs=1000):\n",
    "    \"\"\" vec is a vector that contains the number of neurons in each layer. \n",
    "        The input parameters are considered as the first layer \n",
    "        Input:\n",
    "            vec = list containing the neural network geometry\n",
    "            indat = numpy array. It contains the training dataset\n",
    "            res = numpy array. It contains the target of the dataset\n",
    "            eta = float. step in the gradient descent\n",
    "            tol = float. Error tolerance\n",
    "            epochs = integer. Number of epochs, set by default to 1000\n",
    "        Return:\n",
    "            wf = list of ndarrays. It contains the calculated weigths for each layer\n",
    "            wb = list of ndarrays. It contains the calculated bias for each layer\n",
    "    \"\"\"\n",
    "    siz = len(vec)\n",
    "    sizdata = len(indat)\n",
    "    vals= np.array(indat) \n",
    "    wi, bi = [], [] \n",
    "    \n",
    "#--------------------- initialization ---------------------#  \n",
    "    for j in range(siz - 1):\n",
    "        mm = arrays(vec[j + 1], vec[j], j + 7)\n",
    "        ww, bb = mm.matrix(), mm.vec()\n",
    "        wi.append(ww)\n",
    "        bi.append(bb)  \n",
    "#-----------------------------------------------------------       \n",
    "    epoca = 0 \n",
    "    while True:\n",
    "        eerr = True\n",
    "        for kk in range(sizdata):\n",
    "            yi = [vals[kk,:]]          \n",
    "            vals1 = vals[kk]\n",
    "            results = transres(res[kk], vec[siz - 1])\n",
    "            y2 = feed_forward(wi, vals1, bi, siz)\n",
    "            for i in range(len(y2)):\n",
    "                yi.append(y2[i])\n",
    "            respred = yi[siz - 1]\n",
    "            erro = resta(respred, results)\n",
    "            erreur = (erro**2).mean()\n",
    "            if erreur >= tol:\n",
    "                wi, bi = back_propagation(wi, bi, respred, yi, results, siz, eta)\n",
    "                eerr = True\n",
    "            wf, bf = wi, bi       \n",
    "        epoca += 1 \n",
    "        if (epoca % 50 == 0 ):\n",
    "            print('epoca: ', epoca, ', error: ', erreur)\n",
    "            \n",
    "        if eerr == False or epoca == epochs:\n",
    "            break                     \n",
    "    return (wf, bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results start here\n",
      "epoca:  50 , error:  0.21874157400801075\n",
      "epoca:  100 , error:  0.2191581322379285\n",
      "epoca:  150 , error:  0.21964107496965224\n",
      "epoca:  200 , error:  0.21998556012335255\n",
      "epoca:  250 , error:  0.12062354571939149\n",
      "epoca:  300 , error:  0.011341022504714643\n",
      "epoca:  350 , error:  0.024747153049116354\n",
      "epoca:  400 , error:  0.013012578418722798\n",
      "epoca:  450 , error:  0.007680585283179974\n",
      "epoca:  500 , error:  0.006351039463018221\n",
      "epoca:  550 , error:  0.004221222087347685\n",
      "epoca:  600 , error:  0.0034504111109376102\n",
      "epoca:  650 , error:  0.003721056752346078\n",
      "epoca:  700 , error:  0.0024046452822704214\n",
      "epoca:  750 , error:  0.0013718438112620462\n",
      "epoca:  800 , error:  0.0037840815822902034\n",
      "epoca:  850 , error:  0.002106895636745465\n",
      "epoca:  900 , error:  0.002736074800261605\n",
      "epoca:  950 , error:  0.0029510224172958834\n",
      "epoca:  1000 , error:  0.0028659471189049044\n",
      "[2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0] predicted values\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0] True values\n",
      "accuracy of the method:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(iris.data,iris.target, test_size=0.2, random_state=0)\n",
    "\n",
    "Nlayer1 = len(x_train[0]) # To know the size of the first layer\n",
    "red = [Nlayer1, 3, 3, 3] # Geometry of the Neural network (last value should be the number of classes in the dataset)\n",
    "eta, tol = 0.05, 1e-4\n",
    "print(\"The results start here\")\n",
    "wajust, bajust = network(red, x_train, y_train, eta, tol, 1000)\n",
    "\n",
    "\n",
    "def predict(x_teste, wajust, bajust):\n",
    "    \"\"\" prediction. It output the probabilities of belonging to a determined class\n",
    "        Input:\n",
    "            x_teste = numpy array. Target of the test set.\n",
    "            wajust = list of ndarrays. Weigth matrix for each layer\n",
    "            bajust = list of ndarrays. bias array for each layer\n",
    "        Return: \n",
    "            sol = list of numpy arrays. It containts the probability for each class for each line in x_teste\n",
    "    \"\"\"\n",
    "    siz = np.shape(x_teste)\n",
    "    layersnum = len(red)\n",
    "    vals = np.array(x_teste)\n",
    "    sol = []\n",
    "    for k in range(siz[0]):\n",
    "        vals1 = vals[k] \n",
    "        values = feed_forward(wajust, vals1, bajust, layersnum)\n",
    "        sol.append(values[layersnum-2])\n",
    "    sol = np.array(sol)    \n",
    "    return sol\n",
    "\n",
    "iden = predict(x_test, wajust, bajust)\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\" Function to calculate the accuracy of the model\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    size = len(y_true)\n",
    "    yf = []\n",
    "    for i in range(size):\n",
    "        lista = (y_pred[i].T).tolist()[0]\n",
    "        value = lista.index(max(lista))\n",
    "        yf.append(value)\n",
    "        if value ==  y_true[i]:\n",
    "            total += 1\n",
    "    return round(total*100 / size, 2), yf \n",
    "\n",
    "error, yf = accuracy(iden, y_test)\n",
    "print(yf,'predicted values')\n",
    "print(y_test, 'True values')\n",
    "print('accuracy of the method: ', str(error) + ' %') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
